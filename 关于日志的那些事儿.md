# 关于日志那些事儿

## 日志定义

日志是对每天发生的情况所作的记录。从维基百科检索到以下信息：

* **非计算机领域(日志=日记)**

	>[日记](https://zh.wikipedia.org/wiki/%E6%97%A5%E8%AE%B0)是以日期为排列顺序的笔记。一开始人们用日记来记录天气、事件一直到个人的心理感受、思想深处。日记可以是记录将要做的事情的，也可以记录已经发生的事情和心情。

* **计算机领域**
	>在计算机领域，[日志文件](https://zh.wikipedia.org/wiki/%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6)（logfile）是一个记录了发生在运行中的操作系统或其他软件中的事件的文件，或者记录了在网络聊天软件的用户之间发送的消息。日志记录（Logging）是指保存日志的行为。最简单的做法是将日志写入单个存放日志的文件。
	许多操作系统、软件框架和程序都包含日志系统。广泛使用的一项日志标准是syslog，它在互联网工程任务组（IETF）的RFC 5424中定义。syslog标准使专门的标准化子系统得以生成、过滤、记录和分析日志消息。这可以减轻软件开发人员设计和编写自己的临时日志系统的难度。

## 日志用处

* **快速准确定位线上问题**

	通过查阅日志文件，对线上问题进行跟踪

* **发现系统瓶颈**

	对日志文件记录的性能信息进行分析，发现系统的瓶颈，如：应用事务处理能力(TPS：每秒内的事务数)、数据库存储能力等

* **预警系统潜在风险**

	解析日志，发现系统可能存在的问题，及时预警，如：慢SQL、内存溢出、网络延迟或断开等

* **挖掘产品最大价值**
 
	对日志进行分析，生成报表数据，分析数据可以挖掘产品的更大价值

* **基于日志实现数据备份与恢复**

	系统通过记录操作日志，可以对数据进行备份及后期的数据恢复等，如：MySQL可通过binary log做主备之间的数据同步及数据恢复等

## 日志类型

* **行为日志**
 
	记录用户在site中的行为，可以对用户行为做进一步的数据分析

* **访问日志**
 
	记录系统访问情况，可以监控统计流量、限流，分析模块访问情况，屏蔽恶意访问等

* **错误日志**

	记录异常信息，便于生产问题的排查

* **性能日志**
 
	记录内存使用情况，查询缓慢的数据库SQL，耗时较长的逻辑等，可用于性能监控与性能优化

* **数据库操作日志**
 
	记录对数据库执行的操作，比如MySQL的binlog日志，使用该日志可以进行主备同步、数据恢复等


## 日志级别

|  级别  | 描述 |
| ------------- | ------------- |
| ALL  | 所有级别，包括定制级别  |
| TRACE  | 比 DEBUG 级别的粒度更细  |
| DEBUG  | 指明细致的事件信息，对调试应用最有用 |
| INFO  | 指明描述信息，从粗粒度上描述了应用运行过程  |
| WARN  | 指明潜在的有害状况  |
| ERROR  | 指明错误事件，但应用可能还能继续运行  |
| FATAL  | 指明非常严重的错误事件，可能会导致应用终止执行  |
| OFF  | 最高级别，用于关闭日志  |
 
## 日志规约

* **日志须包含时间戳与标识符**

	说明标识符标记的事件在什么时候发生，标识符可以是错误编码(error code)，如下所示：

	>[18/11/11 22:22:22:22] [fbfa1260-8b32-4270-8a54-b09c8592640d] Error occurred.

* **日志须包含上下文**

	>[18/11/11 22:22:22:22] [fbfa1260-8b32-4270-8a54-b09c8592640d] Error occurred.
	
	看到这条日志，会有很多疑问：Error occurred? What error? In what module? Was it a big deal? Did the entire application crash, or was it just that some user entered “Joe Smith” in the zip code field?

	因此，日志内容须包含上下文：在什么模块，发生了什么事情，事情重要性或严重性等级，事情主人公等。通常日志的读者是人类或程序，所以规范的日志便于人阅读与机器分析。

* **使用键值对或JSON格式存储日志**

	程序对日志的解析通常会对字符串进行截取、正则匹配等操作，为了是这些变得更加简单，通常会使用key-value方式来存储日志：

	>LOG_MODULE INFO com.cjz.user.controller.update:111 - requestId=fbfa1260-8b32-4270-8a54-b09c8592640d, ip=10.200.98.220, message=update user info, timestamp=18/11/11 22:22:22:22

	如果你愿意，可以使用JSON格式存储：

	>{
	"url": "POST /PutData?Category=YunOsAccountOpLog&AccessKeyId=U0Ujpek********&Date=Fri, 28 Jun 2013 06:53:30 GMT&Topic=raw&Signature=pD12XYLmGxKQ+mkd6x7hAgQ7b1c= HTTP/1.1",
	"ip": "10.200.98.220",
	"user-agent": "aliyun-sdk-java",
	"request": {
		"status": "200",
		"latency": "18204"
	},
	"time": "2018-11-11 22"
	}

* **谨慎地记录日志**

	生产环境禁止输出debug日志，有选择地输出info日志，大量地输出无效日志，不利于系统性能的提升，也不利于快速定位错误点

* **避免重复打印日志，浪费磁盘空间**

	避免在程序中重复打印日志，造成磁盘空间的浪费，如下代码：

	~~~
	public File GetFile() {
    	while (!_fileFetcher.IsReady)
       		_logger.Log("Waiting for file fetcher to be ready.");
	
   	return _fileFetcher.FetchFile();
	}
	~~~

* **日志使用条件或占位符的输出方式**

	条件：
	~~~
	if (logger.isDebugEnabled()) {
		logger.debug("Processing trade with id: " + id + " symbol: " + symbol);
	}
	~~~

	占位符：
	~~~
	logger.debug("Processing trade with id: {} symbol : {} ", id, symbol);
	~~~

	使用上面的两种方式输出日志，可以减少构建日志信息的开销，比如字符串操作

* **日志文件推荐保存至少15天，因为有些异常具备以“周”为频次发生的特点**

* **日志文件名按功能、业务、模块命名，写到固定路径，便于阅读查找**

## 日志格式

* **Common Log Format(Access Log Format)**

	NCSA通用日志格式(NCSA Common log format)仅包含基本HTTP访问信息。NCSA通用日志有时也称为访问日志。Common日志包含请求的资源和一些其他信息，但不包含引用，用户代理或cookie信息。该信息包含在单个文件中。

	Common日志文件格式中的字段为：

	>host rfc931 username date:time request statuscode bytes
	
	以下示例显示了使用公共日志文件记录中的值填充的这些字段：

	>125.125.125.125 - dsmith [10/Oct/1999:21:15:05 +0500] "GET /index.html HTTP/1.0" 200 1043
	
	以下是通用日志格式的字段中的字段说明：
	
	* host (125.125.125.125 in the example) 
	
		发出HTTP资源请求的HTTP客户端的IP地址或主机/子域名。

	* rfc931 ("-" in the example) 
	
		用于标识发出HTTP请求的客户端的标识符。如果不存在值，则替换“ - ”。

	* username (dsmith in the example) 

		客户端用于身份验证的用户名（或用户ID）。如果不存在值，则替换“ - ”。

	* date:time timezone ([10/Oct/1999:21:15:05 +0500] in the example) 
	
		HTTP请求的日期和时间戳。

		日期/时间字段中的字段是：

		[dd/MMM/yyyy:hh:mm:ss +-hhmm] 

		字段定义如下：

			dd is the day of the month

			MMM is the month

			yyy is the year

			:hh is the hour

			:mm is the minute

			:ss is the seconds

			+-hhmm is the time zone

		实际上，即使是一位数天，这一天通常也会以两位数格式记录。例如，该月的第二天将表示为02。但是，某些HTTP服务器会将单个数字日记录为单个数字。解析日志记录时，您应该知道两种可能的日期表示。
	
	* request ("GET /index.html HTTP/1.0" in the example) 

		HTTP请求。请求字段包含三条信息。主要部分是请求的资源（index.html）。请求字段还包含HTTP方法（GET）和HTTP协议版本（1.0）。

	* statuscode (200 in the example) 

		状态是指示HTTP请求成功或失败的数字代码。

	* bytes (1043 in the example) 

		bytes字段是一个数字字段，包含作为HTTP请求的一部分传输的数据的字节数，不包括HTTP头。

	注：NCSA组合日志格式在NCSA通用日志格式基础上添加了：referrer user_agent cookie

* **Runtime Log Format**

	如何找出最常用的应用程序功能？使用运行时日志。运行时日志是运行时跟踪。此日志是一个简单文件（wlog扩展），其中包含用户在WINDEV应用程序，WINDEV Mobile应用程序或WEBDEV站点上执行的所有操作的详细信息：
	* 有关流程的详细信息，
	* 用户程序及其参数，
	* 线程，
	* 组件。
	
	该文件允许您：
	* 找出应用程序中最常用的操作。
	* 找出哪些过程花费的时间最多。
	* 在触发问题的过程中遵循代码运行（在测试模式下难以隔离）。
	
	开发团队了解应用程序的哪些部分是最常用的，并且可以将其资源集中在要优化的代码上。

	日志文件的名称，可以使用以下元素构建此名称：
	* 可执行文件的目录，始终填充“\”字符。
	* 可执行文件的名称。
	* 日志文件的开始日期。
	* 日志文件的开始时间。
	* 当前用户的名称。
	* 电脑名称。
	* 当前应用程序的当前用户的数据的目录。

## Zipkin & Zipkin服务调用链日志 

* Zipkin

	现代互联网服务通常被实现为复杂的大规模分布式系统。 这些应用程序可能是由不同团队开发的软件模块集合构建的，可能使用不同的编程语言，并且可以跨越多个物理设备跨越数千台计算机。 在这样的环境中，有助于理解系统行为和有关性能问题的推理工具是非常宝贵的。	

	Zipkin是一种分布式跟踪系统。它有助于收集解决微服务架构中的延迟问题所需的时序数据。它管理这些数据的收集和查找。Zipkin的设计基于[Google Dapper](https://ai.google/research/pubs/pub36356)论文。应用程序向Zipkin报告时序数据。Zipkin UI还提供了一个依赖关系图，显示了每个应用程序通过的跟踪请求数。如果要解决延迟问题或错误，可以根据应用程序，跟踪长度，注释或时间戳对所有跟踪进行筛选或排序。选择跟踪后，您可以看到每个跨度所需的总跟踪时间百分比，从而可以识别问题应用程序。

* Zipkin服务调用链日志

	从客户端发起请求到响应完成记为一个trace(跟踪)，一次请求响应对应一条服务调用链，服务与服务之间的调用关系形成了trace tree(跟踪树)。每个跟踪树节点可以理解为服务与服务之间的调用，记为一个span(跨度)，因此一个trace由多个span组成，产生一次服务调用，会记一个span(也称埋点)，最终多个有序的span(listOfSpans)描述了一个trace。其中，span数据模型采用JSON格式数据：

~~~
span => {

	traceId:随机生成的跟踪唯一标识符，在其中的所有span上设置。编码为16或32个小写十六进制字符，对应64或128位。 例如，128位跟踪ID看起来像4e441824ec2b6a44ffdc9bb9a6453df3

	name:描述这个span的逻辑操作，以小写形式表示（例如：rpc method）

	parentId:如果这是跟踪中的根span，则为父spanID或不存在

	id:跟踪内此操作的唯一64位标识符，编码为16个小写十六进制字符，例如ffdc9bb9a6453df3

	kind:如果存在，kind会澄清timestamp，duration和remoteEndpoint。如果不存在，span是局部的或不完整的。与客户端和服务器不同，生产者和消费者spans之间没有直接的关键路径延迟关系。
		* CLIENT
			* timestamp是请求发送到服务器的时刻。(in v1 “cs”)
			* 持续时间是收到响应或错误之前的延迟。(in v1 “cr”-“cs”)
			* remoteEndpoint是服务器。(in v1 “sa”)
		* SERVER
			* timestamp是收到客户端请求的时刻。(in v1 “sr”)
			* 持续时间是发送响应或发生错误之前的延迟。(in v1 “ss”-“sr”)
			* remote_endpoint是客户端。(in v1 “ca”)
		* PRODUCER
			* timestamp是消息发送到目标的时刻。(in v1 “ms”)
			* duration是发送消息的延迟，例如批处理。
			* remoteEndpoint是broker。
		* CONSUMER
			* timestamp是从源接收消息的时刻。(in v1 “mr”)
			* 持续时间是消耗消息的延迟，例如来自积压。
			* remoteEndpoint - 表示代理。如果未知，请保留serviceName。

	timestamp:span开始时间，以微秒为单位，应该使用最精确的测量值。以下三种情况可能不存在：	
		* 已分配span但从未开始（尚未收到时间戳）
		* span的开始事件丢失了
		* 关于完成的span（ex标签）的数据是在事后发送的

	duration:关键路径的持续时间（以微秒为单位）

	debug:True表示存储此span的请求，即使它覆盖了采样策略。当X-B3-Flags标头的值为1时，就是这样。

	shared:如果我们正在为另一个跟踪器（例如，在不同的主机上）启动的span做出贡献，则为真。

	localEndpoint: {
		serviceName:服务拓扑中此节点的小写标签，例如“favstar”。如果未知则缺省。这是跟踪查找和聚合的主要标签，因此它应该是直观和一致的。许多人使用服务发现的名称。

		ipv4:与链接相关的IPv4地址的文本表示。例如：192.168.99.100。如果未知则缺省。

		ipv6:与链接相关的IPv6地址的文本表示。例如：2001：db8 :: c001。如果未知则缺省。首选使用ipv4字段表示映射地址。

		port:根据上下文，这可能是一个监听端口或一个客户端socket。如果未知则缺省。
	}

	remoteEndpoint: {
		serviceName:服务拓扑中此节点的小写标签，例如“favstar”。如果未知则缺省。这是跟踪查找和聚合的主要标签，因此它应该是直观和一致的。许多人使用服务发现的名称。

		ipv4:与链接相关的IPv4地址的文本表示。例如：192.168.99.100。如果未知则缺省。

		ipv6:与链接相关的IPv6地址的文本表示。例如：2001：db8 :: c001。如果未知则缺省。首选使用ipv4字段表示映射地址。

		port:根据上下文，这可能是一个监听端口或一个客户端socket。如果未知则缺省。
	}

	annotations: [
		{
			timestamp:事件时间(将解释延迟的事件与时间戳相关联)，以微秒为单位，应该使用最精确的测量值。
		
			value:通常是指此事件的短标记，例如“error”。虽然可以添加更大的数据，例如垃圾收集细节，但是短事件名称既保持跨度的大小，也很容易搜索。
		}
	]

	tags: {
		< * >：为span添加上下文，用于搜索，查看和分析。例如，键“your_app.version”将允许您按版本查找跟踪。标签“sql.query”不可搜索，但在查看时可以帮助调试。
	}
}
~~~	

## Syslog

* Syslog常被称为系统日志或系统记录，是一种用来在互联网协议（TCP/IP）的网络中传递记录档消息的标准。这个词汇常用来指涉实际的syslog 协议，或者那些提交syslog消息的应用程序或数据库。
	
* syslog协议属于一种主从式协议：syslog发送端会发送出一个小的文字消息（小于1024位组）到syslog接收端。接收端通常名为“syslogd”、“syslog daemon”或syslog服务器。系统日志消息可以被以UDP协议及╱或TCP协议来发送。这些数据是以明码类型被发送。不过由于SSL加密外套（例如Stunnel、sslio或sslwrap等）并非syslog协议本身的一部分，因此可以被用来透过SSL／TLS方式提供一层加密。

* syslog通常被用于信息系统管理及信息安全审核。虽然它有不少缺陷，但仍获得相当多的设备及各种平台的接收端支持。因此syslog能被用来将来自许多不同类型系统的日志记录集成到集中的存储库中。
	
## Systemd's binary log

* Systemd作为Linux系统第一个由Linux内核创建的进程，由它创建的journald是一个负责事件记录的守护进程，只有附加的二进制文件作为其日志文件

		Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。
		日志的配置文件是/etc/systemd/journald.conf。journalctl功能强大，用法非常多。
	
		# 查看所有日志（默认情况下 ，只保存本次启动的日志）
		$ sudo journalctl
		
		# 查看内核日志（不显示应用日志）
		$ sudo journalctl -k
		
		# 查看系统本次启动的日志
		$ sudo journalctl -b
		$ sudo journalctl -b -0
		
		# 查看上一次启动的日志（需更改设置）
		$ sudo journalctl -b -1
		
		# 查看指定时间的日志
		$ sudo journalctl --since="2012-10-30 18:17:16"
		$ sudo journalctl --since "20 min ago"
		$ sudo journalctl --since yesterday
		$ sudo journalctl --since "2015-01-10" --until "2015-01-11 03:00"
		$ sudo journalctl --since 09:00 --until "1 hour ago"
		
		# 显示尾部的最新10行日志
		$ sudo journalctl -n
		
		# 显示尾部指定行数的日志
		$ sudo journalctl -n 20
		
		# 实时滚动显示最新日志
		$ sudo journalctl -f
		
		# 查看指定服务的日志
		$ sudo journalctl /usr/lib/systemd/systemd
		
		# 查看指定进程的日志
		$ sudo journalctl _PID=1
		
		# 查看某个路径的脚本的日志
		$ sudo journalctl /usr/bin/bash
		
		# 查看指定用户的日志
		$ sudo journalctl _UID=33 --since today
		
		# 查看某个 Unit 的日志
		$ sudo journalctl -u nginx.service
		$ sudo journalctl -u nginx.service --since today
		
		# 实时滚动显示某个 Unit 的最新日志
		$ sudo journalctl -u nginx.service -f
		
		# 合并显示多个 Unit 的日志
		$ journalctl -u nginx.service -u php-fpm.service --since today
		
		# 查看指定优先级（及其以上级别）的日志，共有8级
		# 0: emerg
		# 1: alert
		# 2: crit
		# 3: err
		# 4: warning
		# 5: notice
		# 6: info
		# 7: debug
		$ sudo journalctl -p err -b
		
		# 日志默认分页输出，--no-pager 改为正常的标准输出
		$ sudo journalctl --no-pager
		
		# 以 JSON 格式（单行）输出
		$ sudo journalctl -b -u nginx.service -o json
		
		# 以 JSON 格式（多行）输出，可读性更好
		$ sudo journalctl -b -u nginx.serviceqq
		 -o json-pretty
		
		# 显示日志占据的硬盘空间
		$ sudo journalctl --disk-usage
		
		# 指定日志文件占据的最大空间
		$ sudo journalctl --vacuum-size=1G
		
		# 指定日志文件保存多久
		$ sudo journalctl --vacuum-time=1years

## Systemd's binary log VS Syslog

* Systemd's binary log 使用二进制存储结构，可以用于快速索引、搜索；而Syslog在这方面会显得比较慢。

* Systemd's binary log 二进制储存结构保证消息完整性以防止被篡改，但可能遇到这样一种情况，即所述完整性检查失败（很可能是由于某处的错误而不是篡改），而结构仍然很好；Syslog则不会。

* Systemd's binary log 二进制储存结构在一些情况下(停电、驱动故障、强制关机等)容易发生损坏且一旦损坏不容易恢复，需删除损坏部分从新的文件开始；而Syslog则不会有这方面的担忧。

* Systemd's binary log失去了[KISS原则](https://en.wikipedia.org/wiki/KISS_principle)(Keep it simple, stupid principle)；而基于文本的Syslog简单且很有用，因为它是一个平面文本文件。

>由于Systemd's binary log的这些缺陷，它对Syslog做了兼容，可以一起使用。

## 日志滚动归档

* **应对日趋增大的日志文件**
	
	日志文件的体积会随时间逐渐增大，不管是人还是机器操作它都变得费劲，因此日志文件管理变得尤为重要，通常按时间周期或文件大小进行滚动归档。
	在Linux中，日志轮换通常使用logrotate命令执行。该命令可用于在日志轮换后将日志通过电子邮件发送给系统管理员。日期日志也可以被压缩。
	在FreeBSD和macOS中使用newsyslog命令。它具有基于文件大小，时间或间隔（或其任何组合）触发旋转的能力。
	它可以压缩存档并向进程发送信号以重置日志记录。该命令通常作为cron作业运行，具有全自动日志轮换的效果。
	通常，会定期创建新的日志文件，并通过在名称后附加“1”来重命名旧的日志文件。
	每次启动新的日志文件时，旧日志文件的文件名中的数字都会增加1，因此文件会“旋转”数字（因此名称为“日志轮换”）。
	然后可以删除或存档数量超过阈值的旧日志文件以节省空间。

* **logrotate原理**

	在讲logrotate之前，先来讲讲《Unix环境高级编程》第三章文件IO第十小节讲述的文件共享：
	内核使用三种数据结构表示打开文件，它们之间的关系决定了不同进程操作同一份文件可能产生的影响。

	1）每个进程在进程表中都有一个记录项，记录项中包含一张打开文件描述符表，可将其视为一个矢量，每个描述符占用一项。与每个文件描述符相关联的是：
	* 文件描述符标志
	* 指向一个文件表项的指针
	
	2）内核为所有打开文件维持一张文件表。每个文件表项包含：
	* 文件状态标志
	* 当前文件偏移量
	* 指向该文件v节点表项的指针
	
	3）每个打开文件(或设备)都有一个v节点(v-node)结构。v节点包含了文件类型和对此文件进行各种操作函数的指针。对于大多数文件，v节点还包含该文件的i节点(i-node，索引节点)。这些信息是在打开文件时从磁盘上读入内存的，所以，文件的所有相关信息都是随时可用的。例如,i节点包含了文件的所有者、文件长度、指向文件实际数据块在磁盘上所在位置的指针等。

	> Linux没有使用v节点，而是使用了通用i节点结构。虽然两种实现有所不同，但在概念上，v节点与i节点是一样的。两者都指向文件系统持有的i节点结构。
	
	按以上描述与理解，手绘了Linux中三张表之间的关系：

	![](https://github.com/CainGitHub/Blog/blob/master/images/log/open_file_kernel_data_structure.jpg?raw=true)
	
	结合上图，描述下logrotate滚动归档：
	* create方案(不配置copytruncate)：
	> ① 将原来的日志文件重命名，新增日志文件并命名为原日志文件名称；
	>
	> ② 由于写日志进程(如nginx、tomcat等)打开文件时，进程表中有文件描述符，文件描述符中的指针指向内核为打开文件维持的文件表，文件表的指针指向通用i节点，通用i节点的指针指向文件系统i节点，文件系统i节点有可操作磁盘上实际数据块的指针与api，所以写日志进程(如nginx、tomcat等)想往新增日志文件中写内容，logrotate需要通知写日志进程(如nginx、tomcat等)重开新增日志文件改变IO写入目标，这样做到了文件的滚动归档，且不影响程序继续输出日志。
         
	* copytruncate方案(配置copytruncate)：
	> ① 新增日志文件，并将原日志内容拷贝到新增日志文件中；
	> 
	> ② 清空原日志文件中的内容，然后写日志进程(如nginx、tomcat等)继续往原日志文件中写内容，清空与继续写过程，可能存在日志丢失的问题。
	
## 参考文献

* [阿里Java开发手册](https://github.com/alibaba/p3c)

* [Be Kind to Your Log File (And Those Reading It)](https://blog.scalyr.com/2017/10/kind-log-file-reading/)

* [Log File Formats](https://publib.boulder.ibm.com/tividd/td/ITWSA/ITWSA_info45/en_US/HTML/guide/c-logs.html)

* [阿里云日志服务](https://www.alibabacloud.com/help/zh/product/28958.htm?spm=a2c63.p38356.a1.2.5dec6cecpLh43r)

* [Runtime log](https://help.windev.com/?2019030)

* [Syslog message formats](https://help.deepsecurity.trendmicro.com/Events-Alerts/syslog-parsing.html)

* [Systemd Wikipedia](https://en.wikipedia.org/wiki/Systemd)

* [A brief overview and history of systemd — the Linux process manager](https://hackernoon.com/a-brief-overview-and-history-of-systemd-the-linux-process-manager-ca508bee4a33)

* [IBM developerWorks Linux Systemd](https://www.ibm.com/developerworks/cn/linux/1407_liuming_init3/index.html)

* [Why systemd?](http://0pointer.de/blog/projects/why.html)

* [fedora wiki systemd](https://fedoraproject.org/wiki/Systemd/zh-cn)

* [Journalctl to View and Manipulate Systemd Logs](https://www.linuxsecrets.com/3653-journalctl-to-view-and-manipulate-systemd-logs)

* [systemd's binary logs and corruption](https://www.reddit.com/r/linux/comments/1y6q0l/systemds_binary_logs_and_corruption/)

* [Which init system for Debian?](https://lwn.net/Articles/572805/)

* [logrotate机制和原理](https://www.lightxue.com/how-logrotate-works)

* [Zipkin](https://zipkin.io/)

* [Google Dapper](http://systemsandpapers.s3.amazonaws.com/papers/dapper.pdf)
